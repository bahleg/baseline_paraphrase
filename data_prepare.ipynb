{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "качаем Glove, хороший список моделей тут:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/3Top/word2vec-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-02-19 21:25:07--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "100%[======================================>] 862 182 613  617KB/s   in 27m 46s\n",
      "\n",
      "2017-02-19 21:52:53 (505 KB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "используем convert.py из  https://raw.githubusercontent.com/jroakes/glove-to-word2vec/master/convert.py\n",
    "По умолчанию он конвертирует модель размерности 300, мы попробуем размерность 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenBLAS : Your OS does not support AVX instructions. OpenBLAS is using Nehalem kernels as a fallback, which may give poorer performance.\n",
      "OpenBLAS : Your OS does not support AVX instructions. OpenBLAS is using Nehalem kernels as a fallback, which may give poorer performance.\n",
      "/usr/local/lib/python2.7/dist-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "[(u'zealand', 0.9042125940322876), (u'england', 0.7858781814575195), (u'australian', 0.7696145176887512), (u'britain', 0.7670673131942749), (u'canada', 0.7569618821144104), (u'africa', 0.7522280216217041), (u'scotland', 0.7264115214347839), (u'wales', 0.720910906791687), (u'india', 0.704209566116333), (u'indies', 0.6983797550201416)]\n",
      "0.832349418276\n"
     ]
    }
   ],
   "source": [
    "!python convert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "w2v = gensim.models.Word2Vec.load_word2vec_format('./glove_model2.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используем центроид вместо неизвестных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np\n",
    "centroid = np.mean(w2v.syn0, axis=0)\n",
    "print centroid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Качаем архив из http://alt.qcri.org/semeval2015/task2/data/uploads/sts2015-en-post.zip   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем сразу выборки как для RNN, так и для baseline в статье (нужно убедиться что мы все напрогали правильно и RNN работает лучше базовых алгоритмов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def cosine_tokens(tokens1, tokens2):\n",
    "    c1 = Counter(tokens1)\n",
    "    c2 = Counter(tokens2)\n",
    "    intersection = set(c1.keys()) & set(c2.keys())\n",
    "    numerator = sum([c1[x] * c2[x] for x in intersection])\n",
    "    sum1 = sum([c1[x]**2 for x in c1.keys()])\n",
    "    sum2 = sum([c2[x]**2 for x in c2.keys()])\n",
    "    denominator = np.sqrt(sum1) * np.sqrt(sum2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(tokens1, tokens2):\n",
    "    set1 = set(tokens1)\n",
    "    set2 = set(tokens2)\n",
    "    return float(len(set1 | set2))/(len(set1) + len(set2) - len(set1&set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "filename = 'text.clean'\n",
    "X,Y = [],[]\n",
    "X_base = []\n",
    "with open(filename) as inp:    \n",
    "    for line in inp:    \n",
    "        sublines = line.split('\\t')\n",
    "        score = int(np.round(float(sublines[0])).astype(np.uint))\n",
    "        vectors = []\n",
    "        tokens = []\n",
    "        for subline in [sublines[4],sublines[5]]:\n",
    "            subline = re.sub('[^a-z\\s]+', ' ', subline.lower())\n",
    "            tokens.append([t for t in subline.split() if t not in stopwords])\n",
    "            vectors.append([w2v[t] if t in w2v.vocab else centroid for t in tokens[-1] ])\n",
    "        if len(vectors[0])==0 :\n",
    "            vectors[0].append(centroid)\n",
    "        if len(vectors[1])==0:\n",
    "            vectors[1].append(centroid)\n",
    "        X.append(vectors[0])\n",
    "        X.append(vectors[1])\n",
    "        X_base.append([cosine(np.mean(vectors[0], axis=0),np.mean(vectors[1],axis=0)), cosine_tokens(tokens[0], tokens[1]),\n",
    "                      jaccard(tokens[0], tokens[1])])\n",
    "        Y.append(score)\n",
    "idx = range(len(Y))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "X_base = [X_base[i] for i in idx]\n",
    "Y = [Y[i] for i in idx]\n",
    "X_new = []\n",
    "for i in idx:\n",
    "    X_new.append(X[2*i])\n",
    "    X_new.append(X[2*i+1])\n",
    "np.save('semeval_x', X_new)\n",
    "np.save('semeval_x_baseline', X_base)\n",
    "np.save('semeval_y', Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
