{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый эксперимент с RNN, с вариационным выводом\n",
    "\n",
    "В качестве априоного рассматривается распредедение $\\mathcal{N}(\\mathbf{0}, 1000\\mathbf{I})$,\n",
    "в качестве вариационного --- $\\mathcal{N}(\\mathbf{m}, \\beta \\mathbf{I})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import OrderedDict\n",
    "if theano.config.device == 'gpu':\n",
    "    from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "else:\n",
    "    from theano.tensor.shared_randomstreams import RandomStreams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим выборку в отношении 85%/15%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.load('semeval_x.npy')\n",
    "Y= np.load('semeval_y.npy').astype(np.int32)\n",
    "\n",
    "part = int(len(Y)*0.85)\n",
    "\n",
    "max_len = max([len(x) for x in X])\n",
    "X_masked1,X_masked2  = np.zeros((Y.shape[0], max_len, 50)).astype(theano.config.floatX),np.zeros((Y.shape[0], max_len, 50)).astype(theano.config.floatX)\n",
    "Mask1, Mask2 = np.zeros((Y.shape[0], max_len)).astype(theano.config.floatX), np.zeros((Y.shape[0], max_len)).astype(theano.config.floatX)\n",
    "for i in xrange(X.shape[0]/2):\n",
    "    X_masked1[i, :len(X[2*i])] = X[2*i]\n",
    "    X_masked2[i, :len(X[2*i+1])] = X[2*i+1]\n",
    "    Mask1[i,  :len(X[2*i])] = 1.0\n",
    "    Mask2[i,  :len(X[2*i+1])] = 1.0\n",
    "    \n",
    "X_train1, X_test1=X_masked1[:part],  X_masked1[part:],\n",
    "X_train2, X_test2 = X_masked2[:part],X_masked2[part:]\n",
    "\n",
    "M_train1, M_test1= Mask1[:part], Mask1[part:],\n",
    "M_train2, M_test2  = Mask2[:part],Mask2[part:]\n",
    "Y_train,  Y_test = Y[:part], Y[part:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = theano.shared(0.01)\n",
    "\n",
    "prior_log_sigma = theano.shared(np.log(1000.0))\n",
    "prior_mu = theano.shared(0.0)\n",
    "var_log_sigma = theano.shared(np.log(0.01))\n",
    "\n",
    "\n",
    "batch_size = 25\n",
    "hidden_size = 50\n",
    "input_size = 50\n",
    "epoch_num = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание входных тензоров.\n",
    "\n",
    "Для каждой группы параметров из модели создаем переменную <название группы>_mean. В терминах Graves - наше вариационное распределение выглядит как:\n",
    "Q([W_mean, U_mean, b_mean, ...], $e^\\text{var_log_sigma}$)\n",
    "\n",
    "Использовани логарифма в отклонении помогает избежать возможных переполнений и пр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tensor1, X_tensor2 = T.tensor3(), T.tensor3()\n",
    "Mask_matrix1, Mask_matrix2 = T.matrix(), T.matrix()\n",
    "Y_vector = T.ivector()\n",
    "\n",
    "\n",
    "W_mean = theano.shared((np.zeros((input_size, hidden_size))).astype(theano.config.floatX))\n",
    "U_mean = theano.shared((np.zeros((hidden_size, hidden_size)).astype(theano.config.floatX)))\n",
    "b_mean = theano.shared((np.zeros((hidden_size)).astype(theano.config.floatX)))\n",
    "h0_mean = theano.shared((np.zeros((hidden_size)).astype(theano.config.floatX)))\n",
    "softmax_W_mean = theano.shared((np.zeros((2*hidden_size,6)).astype(theano.config.floatX)))\n",
    "softmax_b_mean = theano.shared((np.zeros(6).astype(theano.config.floatX)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сэмплируем параметры.\n",
    "\n",
    "Теперь все наши параметры имеют на одну размерность больше (размер батча $\\times$ старые размерности).\n",
    "С точки зрения технической реализации, единственное, что нам придется изменить --- это заменить перемножение матриц T.dot на перемножение тензоров T.batched_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "W = srng.normal((X_tensor1.shape[0],input_size, hidden_size))*T.exp(var_log_sigma)   + W_mean\n",
    "U = srng.normal((X_tensor1.shape[0],hidden_size, hidden_size))*T.exp(var_log_sigma)   + U_mean\n",
    "b = srng.normal((X_tensor1.shape[0], hidden_size))*T.exp(var_log_sigma)   + b_mean\n",
    "h0 = srng.normal((X_tensor1.shape[0],  hidden_size))*T.exp(var_log_sigma)   + h0_mean\n",
    "softmax_W = srng.normal((X_tensor1.shape[0],2*hidden_size,6))*T.exp(var_log_sigma)   + softmax_W_mean\n",
    "softmax_b = srng.normal((X_tensor1.shape[0],6))*T.exp(var_log_sigma)   + softmax_b_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один шаг кодирования:\n",
    "    $$h_i = \\text{tanh}(\\mathbf{XW} + \\mathbf{h_{i-1}U} + \\mathbf{b}) $$\n",
    "    \n",
    "XW уже перемножено для оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_step(XW_matrix, hidden):    \n",
    "    return T.tanh(XW_matrix  + T.batched_dot(hidden, U) + b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обертка кодирования с учетом маски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def masked_step( XW, hidden,   mask):\n",
    "\n",
    "        hid_new = encode_step(XW, hidden)\n",
    "        mask_axis = T.tile(mask, (XW.shape[1], 1)).T\n",
    "        hid_out = T.switch(mask_axis, hid_new, hidden)\n",
    "        return hid_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_results = [] #test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XW1 = T.batched_dot(X_tensor1, W)\n",
    "XW2 = T.batched_dot(X_tensor2, W)\n",
    "\n",
    "hiddens1, hiddens2 = [h0], [h0]\n",
    "for i in xrange(max_len):\n",
    "    hiddens1.append(masked_step(XW1[:,i,:], hiddens1[-1],  Mask_matrix1[:,i]))\n",
    "    hiddens2.append(masked_step(XW2[:,i,:], hiddens2[-1],  Mask_matrix2[:,i]))\n",
    "output = T.nnet.softmax(T.batched_dot(T.concatenate([hiddens1[-1], hiddens2[-1]], axis=1 ), softmax_W) + softmax_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "softmax_cost = -T.sum(T.log(output)[T.arange(Y_vector.shape[0]), Y_vector])*X_train1.shape[0]/X_tensor1.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "расстояние KL для двух гауссовых распределений.\n",
    "\n",
    "Смотри русскую вики, в их терминах нулевой индекс соответствует вариационному распределению,\n",
    "первый индекс - априорному"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_param_mean = [W_mean.flatten(),U_mean.flatten(), h0_mean.flatten(), b_mean.flatten(),softmax_W_mean.flatten(),softmax_b_mean.flatten()]\n",
    "all_param_tensor = T.concatenate(all_param_mean)\n",
    "first_part = T.exp(2*var_log_sigma)/T.exp(2*prior_log_sigma)\n",
    "second_part = T.dot(prior_mu- all_param_tensor,(prior_mu-all_param_tensor).T)/T.exp(2*prior_log_sigma)\n",
    "third_part = -np.sum([len(i.eval()) for i in all_param_mean])\n",
    "fourth_part = 2*prior_log_sigma - 2*var_log_sigma \n",
    "KLD = 0.5* (first_part + second_part + third_part + fourth_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = softmax_cost  + KLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код adagrad из lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasagne_adagrad(loss, params, learning_rate=1.0, epsilon=1e-6):   \n",
    "    grads = [T.grad(loss,p) for p in params]\n",
    "    updates = OrderedDict()\n",
    "\n",
    "    for param, grad in zip(params, grads):\n",
    "        value = param.get_value(borrow=True)\n",
    "        accu = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                             broadcastable=param.broadcastable)\n",
    "        accu_new = accu + grad ** 2\n",
    "        updates[accu] = accu_new\n",
    "        updates[param] = param - (learning_rate * grad /\n",
    "                                  T.sqrt(accu_new + epsilon))\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компиляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_to_optimize  = [W_mean,U_mean,b_mean,softmax_W_mean,softmax_b_mean,h0_mean, var_log_sigma]\n",
    "train_fn = theano.function([X_tensor1, X_tensor2, Mask_matrix1, Mask_matrix2,  Y_vector], cost,  \n",
    "                           updates=lasagne_adagrad(cost, params_to_optimize, learning_rate=lr), \n",
    "                           on_unused_input='ignore' )\n",
    "predict_fn = theano.function([X_tensor1, X_tensor2, Mask_matrix1, Mask_matrix2], output, on_unused_input='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидация будет происходить на каждой десятой эпохе.\n",
    "Выбирается случайная сбалансированная подвыборка из  тестовой выборки и считается их macro-мера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def my_eval():\n",
    "    print 'validation'    \n",
    "    min_class = min([len(np.where(Y_test==i)[0]) for i in range(6)])\n",
    "    results = []\n",
    "    for _ in xrange(10):\n",
    "        idx = []\n",
    "        for i in range(6):\n",
    "            class_idx = np.where(Y_test==i)[0].tolist()\n",
    "            idx.extend(sample(class_idx, min_class))\n",
    "        pred = np.argmax(predict_fn(X_test1[idx], X_test2[idx], M_test1[idx], M_test2[idx]), axis=1)\n",
    "        results.append(f1_score(Y_test[idx], pred, average='macro'))\n",
    "    print np.mean(results), np.std(results)\n",
    "    train_results.append(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Непосредственно запуск оптимизации.\n",
    "Каждую эпоху смотрим среднее по батчам значение Evidence. В принципе, на основе этого показателя можно сделать раннюю остановку.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "7751.01861109\n",
      "0.261316251838\n",
      "validation\n",
      "0.207374459576 0.00904126180089\n",
      "Epoch 1\n",
      "7368.20348426\n",
      "Epoch 2\n",
      "7288.18688508\n",
      "Epoch 3\n",
      "7218.33364078\n",
      "Epoch 4\n",
      "7200.08060743\n",
      "Epoch 5\n",
      "7165.36822853\n",
      "Epoch 6\n",
      "7144.24684106\n",
      "Epoch 7\n",
      "7129.23660407\n",
      "Epoch 8\n",
      "7099.82774857\n",
      "Epoch 9\n",
      "7090.72143362\n",
      "Epoch 10\n",
      "7070.66637171\n",
      "0.33356965524\n",
      "validation\n",
      "0.291289155372 0.00983839797782\n",
      "Epoch 11\n",
      "7052.12288709\n",
      "Epoch 12\n",
      "7040.60261961\n",
      "Epoch 13\n",
      "7022.00553541\n",
      "Epoch 14\n",
      "7001.25349624\n",
      "Epoch 15\n",
      "6995.40918029\n",
      "Epoch 16\n",
      "6979.34943259\n",
      "Epoch 17\n",
      "6959.77400488\n",
      "Epoch 18\n",
      "6946.39785854\n",
      "Epoch 19\n",
      "6944.00406667\n",
      "Epoch 20\n",
      "6923.17446163\n",
      "0.350917703652\n",
      "validation\n",
      "0.314468172979 0.0126526550972\n",
      "Epoch 21\n",
      "6915.48668116\n",
      "Epoch 22\n",
      "6904.05281996\n",
      "Epoch 23\n",
      "6895.41382684\n",
      "Epoch 24\n",
      "6886.95656902\n",
      "Epoch 25\n",
      "6861.25562497\n",
      "Epoch 26\n",
      "6859.43768698\n",
      "Epoch 27\n",
      "6851.93125793\n",
      "Epoch 28\n",
      "6846.24949813\n",
      "Epoch 29\n",
      "6837.16604334\n",
      "Epoch 30\n",
      "6841.20226376\n",
      "0.363514328423\n",
      "validation\n",
      "0.317907470203 0.010821488463\n",
      "Epoch 31\n",
      "6818.49318695\n",
      "Epoch 32\n",
      "6811.35424016\n",
      "Epoch 33\n",
      "6808.49638589\n",
      "Epoch 34\n",
      "6807.00340876\n",
      "Epoch 35\n",
      "6799.78610195\n",
      "Epoch 36\n",
      "6791.5537475\n",
      "Epoch 37\n",
      "6776.9767205\n",
      "Epoch 38\n",
      "6764.51586022\n",
      "Epoch 39\n",
      "6764.34302172\n",
      "Epoch 40\n",
      "6750.86144832\n",
      "0.374162737077\n",
      "validation\n",
      "0.314203481693 0.00914244639488\n",
      "Epoch 41\n",
      "6757.10916754\n",
      "Epoch 42\n",
      "6738.74055325\n",
      "Epoch 43\n",
      "6739.55817482\n",
      "Epoch 44\n",
      "6724.296119\n",
      "Epoch 45\n",
      "6712.49658901\n",
      "Epoch 46\n",
      "6720.76717123\n",
      "Epoch 47\n",
      "6701.09436858\n",
      "Epoch 48\n",
      "6709.86815083\n",
      "Epoch 49\n",
      "6707.03955481\n",
      "Epoch 50\n",
      "6688.12173662\n",
      "0.381165244275\n",
      "validation\n",
      "0.326631482589 0.0189300937026\n",
      "Epoch 51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-6882730a0a3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM_train2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mbatch_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.2-py2.7.egg/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.2-py2.7.egg/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in xrange(1000):\n",
    "    print 'Epoch', epoch\n",
    "    batch_results = []\n",
    "    for batch_start in xrange(0, X_train1.shape[0] + batch_size,  batch_size):\n",
    "        batch_ids = range(batch_start, min(X_train1.shape[0], batch_start+batch_size))\n",
    "        if len(batch_ids)==0:\n",
    "            break\n",
    "        x1 = X_train1[batch_ids]\n",
    "        x2 = X_train2[batch_ids]\n",
    "        m1 = M_train1[batch_ids]\n",
    "        m2 = M_train2[batch_ids]\n",
    "        y = Y_train[batch_ids]        \n",
    "        batch_results.append( train_fn(x1,x2, m1, m2, y))\n",
    "    print np.mean(batch_results) \n",
    "    if epoch%10==0:\n",
    "        y_pred = np.argmax(predict_fn(X_train1, X_train2, M_train1, M_train2), axis=1)\n",
    "        print f1_score(Y_train, y_pred, average='macro')\n",
    "        my_eval()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
